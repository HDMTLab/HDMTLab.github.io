<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="google-site-verification" content="aSoPdESQFn8tbJg0HUTpmjSlG-FVdvf1QAVgNiGzb9U" /> 
  <meta name="keywords" content="junyongpark, Seoul National University, Statistics, 서울대학교, 통계학과, 박준용, multiple testing, high-dimensional classification, mean vector estimation">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>2026 Workshop on Robust Inference for High-Dimensional Complex Data</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,600">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Roboto" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script src="//code.jquery.com/jquery-1.12.0.min.js"></script>
  <link href="http://localhost:4000/css/zoom.css" rel="stylesheet">
  <script src="http://localhost:4000/js/zoom.js"></script>
  <script src="http://localhost:4000/js/transition.js"></script>

  <link rel="stylesheet" href="/style.css">

  <!-- open graph -->

  
  
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="article">
  <meta property="og:url" content="http://localhost:4000/workshop/workshop2026winter/">
  <meta property="og:title" content="2026 Workshop on Robust Inference for High-Dimensional Complex Data">
  <meta property="og:site_name" content="High Dimensional Multiple Testing Lab">
  <meta property="og:description" content="
  
  

2026 Workshop on Robust Inference for High-Dimensional Complex Data



Introduction

The 2026 Workshop on Robust Inference for High-Dimensi..." />
  <meta property="og:image" content="http://localhost:4000/images/logo/logo_square.jpg">

</head>

<script>
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//kordinglab.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<body id="page-top" style="padding-top: 7em;">

    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class='navbar-brand page-scroll' href='/'>
              <span style='font-family:"Open Sans" font-weight:300'>HDMT Lab</span>
              </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <ul class="nav navbar-nav navbar-right">
                      
                      <li><a class='name' href="/">Home</a></li>
                      
                      <li><a class='name' href="/research">Research</a></li>
                      
                      <li><a class='name' href="/publication">Publications</a></li>
                      
                      <li><a class='name' href="/people">People</a></li>
                      
                      <li><a class='name' href="/gallery">Gallery</a></li>
                      
                      <li><a class='name' href="/workshop">Workshop</a></li>
                      
                    </ul>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
</nav>

    <div class="container content page">
  <!-- <h1 class="page-title">2026 Workshop on Robust Inference for High-Dimensional Complex Data</h1> -->
  <style>
.talk-card {
  border: 1px solid #e0e0e0;
  border-radius: 8px;
  padding: 0.6em 1em;
  margin: 1em 0;
  background: #fafafa;
  transition: box-shadow 0.2s ease;
}

.talk-card:hover {
  box-shadow: 0 4px 12px rgba(0,0,0,0.06);
}

.talk-card summary {
  cursor: pointer;
  list-style: none;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.talk-card summary::-webkit-details-marker {
  display: none;
}

.talk-title {
  font-weight: 600;
}

.talk-speaker {
  /* font-style: italic; */
  color: #555;
}

.talk-abstract {
  margin-top: 0.8em;
  padding-top: 0.8em;
  border-top: 1px solid #ddd;
  line-height: 1.6;
}
.talk-abstract {
  animation: fadeIn 0.25s ease-in;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(-4px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.session-title {
  display: flex;
  justify-content: space-between;
  align-items: baseline;
  margin-top: 2.2em;
  margin-bottom: 0.8em;
  padding-bottom: 0.3em;
  border-bottom: 2px solid #ddd;
  font-size: 1.4em;
  font-weight: 600;
}


.session-time {
  font-size: 0.9em;
  font-weight: normal;
  color: #666;
  white-space: nowrap;
}

.day-title {
  margin-top: 2em;
  margin-bottom: 1em;
  font-size: 2em;
  font-weight: 700;
  border-bottom: 3px solid #000;
}
</style>

<h1 id="2026-workshop-on-robust-inference-for-high-dimensional-complex-data">2026 Workshop on Robust Inference for High-Dimensional Complex Data</h1>

<hr />

<h2 id="introduction">Introduction</h2>

<p>The <em>2026 Workshop on Robust Inference for High-Dimensional Complex Data</em> aims to bring together researchers to discuss recent advances in robust statistical inference for modern complex data settings. The workshop focuses on methodological developments that ensure reliable inference in the presence of high dimensionality, dependence, and structural complexity.</p>

<p>The sessions will cover a range of contemporary topics, including <em>multiple testing, e-values, conformal prediction, false discovery rate (FDR) control, test for means, empirical Bayes, and other related topics</em>. These methodologies will be discussed in the context of complex data types such as <em>high-dimensional data, online or streaming data, functional data, and tensor-valued data</em>.</p>

<p>Through presentations and discussions, the workshop seeks to foster the exchange of ideas on unifying principles and practical challenges in robust inference, and to encourage collaboration among researchers working on theoretical foundations as well as methodological and applied aspects of modern statistics. Each participant will give a presentation of approximately 25 minutes on their research, followed by a question-and-answer session.</p>

<hr />

<h2 id="date--venue">Date &amp; Venue</h2>

<ul>
  <li>January 21, 2026, 13:00 – January 22, 2026, 12:00
<!-- - 2026.01.21 13:00 - 2026.01.22 12:00 -->
<!-- - 13:00, Jan 21, 2026 – 12:00, Jan 22, 2026 --></li>
  <li>Room 806, Convention Center, Siheung Campus, Seoul National University
<!-- - 서울대학교 시흥캠퍼스 컨벤션센터 806호 --></li>
</ul>

<hr />

<h2 id="program-and-schedule">Program and Schedule</h2>

<!-- site.data.{yml 파일명}만 수정해서 사용 (원본 파일은 data/workshop_2026winter.yml) -->

<h1 class="day-title">Day 1 (January 21)</h1>

<h2 class="session-title">
<span class="session-name">Registration</span>

<span class="session-time">13:00–13:10</span>

</h2>

<h2 class="session-title">
<span class="session-name">Opening Remark</span>

<span class="session-time">13:10–13:20</span>

</h2>

<h2 class="session-title">
<span class="session-name">Session 1: Hypothesis Test for High-Dimensional Means</span>

<span class="session-time">13:20–14:35</span>

</h2>

<details class="talk-card">
    <summary>
    <span class="talk-title">Random Direction Tests for a Multivariate Normal Mean under Polyhedral Cone Constraints</span>
    <span class="talk-speaker">고준혁 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    We study hypothesis testing for a multivariate normal mean subject to linear inequality constraints, where the parameter space is a polyhedral cone. Classical procedures for one-sided multivariate testing—most notably the generalized likelihood ratio test (GLRT) and O’Brien’s test~\cite{Tang}—are well understood when the cone is the nonnegative orthant, but their behavior can be unstable for general cones and under unknown covariance. Building on an ensemble idea~\cite{Ensemble}, we propose four new tests—the Single Direction Test (SDT), the Ensemble Direction Test (EDT), the Hartung Direction Test (HDT), and the Maximum Direction Test (MDT)—that aggregate $p$-values using randomly generated directions in the cone. Across a wide range of alternatives and covariance structures, our simulations show that the EDT attains higher power than the GLRT, which is often conservative in the unknown-covariance setting. On the other hand, the EDT can exhibit inflated type~I error at moderate significance levels and can be computationally expensive in high-dimensional settings.

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">Projection tests for mean vector in high dimension</span>
    <span class="talk-speaker">송휘종 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">Two-Sample Projection Test for High-Dimensional Functional Data</span>
    <span class="talk-speaker">김현성 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    We propose a novel two-sample test for high-dimensional functional data, termed the Data-Splitting Projection Test for High-dimensional Functional Data (DSPT-HFD). In settings where the number of functional covariates $p$ far exceeds the sample size $n$, existing methods often face computational challenges or lack theoretical guarantees. The proposed method utilizes a data-splitting strategy to estimate an optimal projection direction that maximizes group mean differences using one data subset, and performs a two-sample test on the projected univariate samples using the remaining subset. The optimal projection direction is estimated by solving a penalized least squares problem with a group non-convex penalty. We theoretically establish the consistency of the estimated direction and prove that the asymptotic power of the test converges to one. Extensive simulation studies and applications to ADHD-200 and EEG datasets demonstrate that DSPT-HFD achieves superior power compared to existing methods while robustly controlling type-I error rates, even under violations of standard assumptions.

    </div>
</details>

<h2 class="session-title">
<span class="session-name">Session 2: Empirical Bayes with Application</span>

<span class="session-time">14:45–16:00</span>

</h2>

<details class="talk-card">
    <summary>
    <span class="talk-title">Sharpening Variance Estimation: An Empirical Bayes Approach under Mean-Variance <br /> Dependence</span>
    <span class="talk-speaker">송채원 (숙명여대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">모수적 경험적 베이즈의 확장: 이분산성 데이터에서의 SURE,URE 기반의 Robust한 축소추정량</span>
    <span class="talk-speaker">홍지민 (숙명여대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">Nonparametric maximum likelihood estimation for multivariate normal models and <br /> its applications to classification</span>
    <span class="talk-speaker">오승연 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<h2 class="session-title">
<span class="session-name">Session 3: Online Inference with E-values</span>

<span class="session-time">16:10–17:00</span>

</h2>

<details class="talk-card">
    <summary>
    <span class="talk-title">Admissible Online True Discovery Guarantees: Closed Testing and Why e-Values Are Necessary</span>
    <span class="talk-speaker">손유안 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    In contemporary research, data scientists often test an infinite sequence of hypotheses $H_1, H_2, \dots$ one by one, requiring real-time decisions without knowledge of future hypotheses or data. This presentation reviews recent developments in online multiple testing, specifically focusing on the goal of providing simultaneous lower bounds for the number of true discoveries in data-adaptively chosen rejection sets.While it has been established in offline multiple testing that simultaneous inference is admissible if and only if it proceeds through closed testing, this talk discusses the extension of this result to the online setting using the recent online closure principle. We explore the key theoretical insight that utilizing an anytime-valid test for each intersection hypothesis is necessary, thereby connecting two distinct branches of literature: online testing of multiple hypotheses and sequential anytime-valid testing of a single hypothesis.The review further covers the construction of a new online closed testing procedure and a corresponding short-cut with a true discovery guarantee based on multiplying sequential e-values. We will discuss how this general procedure not only offers uniform improvements over state-of-the-art methods but also facilitates the creation of powerful new procedures. Finally, we examine novel strategies for hedging and boosting sequential e-values to increase power, along with the first online true discovery procedures for exchangeable and arbitrarily dependent e-values.

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">Post-hoc selection of significance level</span>
    <span class="talk-speaker">황서화 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    The validity of classical hypothesis testing requires the significance level α be fixed before any statistical analysis takes place. This presentation begins by discussing why this is a stringent requirement. For instance, it prohibits updating α during (or after) an experiment due to changing concern about the cost of false positives, or to reflect unexpectedly strong evidence against the null. Perhaps most disturbingly, witnessing a p-value p ≪ α vs p = α − ϵ for tiny ϵ &gt; 0 has no (statistical) relevance for any downstream decision-making.Focusing on developments following the recent work of Grünwald (2024), this talk reviews a theory of post-hoc hypothesis testing that enables α to be chosen after seeing and analyzing the data. We examine the concept of Γ-admissibility, introduced to study “good” post-hoc tests, where Γ  is a set of adversaries which map the data to a significance level. The discussion covers the classification of Γ -admissible rules for various sets Γ, highlighting the finding that they must be based on e-values, and demonstrating how they recover the Neyman-Pearson lemma when Γ is the constant map. Finally, we present a Rao-Blackwellization result provided in the literature, which proves that the expected utility of an e-value can be improved (for any concave utility) by conditioning on a sufficient statistic.

    </div>
</details>

<h2 class="session-title">
<span class="session-name">Session 4: Conformal Prediction</span>

<span class="session-time">17:10–18:00</span>

</h2>

<details class="talk-card">
    <summary>
    <span class="talk-title">Decaying-Step Online Conformal Prediction</span>
    <span class="talk-speaker">박지호 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    This presentation reviews a novel method for online conformal prediction that utilizes decaying step sizes. We discuss how, similar to previous approaches, this method possesses a retrospective guarantee of coverage for arbitrary sequences. However, the presentation highlights a key distinction: unlike previous methods, the proposed approach enables the simultaneous estimation of a population quantile when it exists. We further examine theoretical and experimental results indicating substantially improved practical properties. In particular, we focus on the finding that when the distribution is stable, the coverage remains close to the desired level for every time point, rather than merely on average over the observed sequence.

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">Shrinkage-Clustered Conformal Prediction</span>
    <span class="talk-speaker">김지수 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    Standard conformal prediction provides valid marginal coverage but often fails to ensure fairness or conditional reliability across classes. Class-conditional conformal prediction (CC-CP) mitigates this issue by calibrating within each class or class cluster. Although its performance deteriorates when calibration data are limited for minority classes, leading to unstable or excessively large prediction sets. We propose Shrinkage Class-Clustered Conformal Prediction (SCC—CP), a distribution free method that constructs conformal prediction sets by adaptively shrinking cluster-level conformal quantile toward a global conformal quantile using data-driven weights. 

    </div>
</details>

<h2 class="session-title">
<span class="session-name">Dinner</span>

<span class="session-time">돝집 거북섬점</span>

</h2>

<h2 class="session-title">
<span class="session-name">Accommodation</span>

<span class="session-time">시흥 웨이브 엠 호텔 웨스트 호텔</span>

</h2>

<h1 class="day-title">Day 2 (January 22)</h1>

<h2 class="session-title">
<span class="session-name">Breakfast</span>

<span class="session-time">시흥 웨이브 엠 호텔 웨스트 호텔</span>

</h2>

<h2 class="session-title">
<span class="session-name">Session 4: Multiple Testing with FDR Control</span>

<span class="session-time">09:30–10:45</span>

</h2>

<details class="talk-card">
    <summary>
    <span class="talk-title">Introduction to compound p-values</span>
    <span class="talk-speaker">허종원 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    In the setting of multiple testing, compound p-values generalize p-values by asking for superuniformity to hold only on average across all true nulls. This presentation reviews the properties of the Benjamini–Hochberg procedure applied to such compound p-values. We examine theoretical results under independence, which establish that the false discovery rate (FDR) is at most 1.93α (where α is the nominal level), and we discuss a specific distribution for which the FDR is shown to be 7α/6. The talk also covers the scenario where all nulls are true, highlighting that the upper bound can be improved to α+2α2, with a corresponding worst-case lower bound of α+α2/4. In contrast, under positive dependence, we discuss findings demonstrating that the FDR can be inflated by a factor of O(log m), where $m$ is the number of hypotheses. Finally, we illustrate numerous examples of settings where compound p-values arise in practice, focusing on cases where sufficient information to compute non-trivial p-values is lacking, or where the approach facilitates a more powerful analysis.

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">Symmetrized Aggregation for FDR Control under General Dependence</span>
    <span class="talk-speaker">김규람 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    This presentation reviews a new class of distribution-free multiple testing rules for false discovery rate (FDR) control under general dependence. We discuss a key element of the proposed method: a symmetrized data aggregation (SDA) approach to incorporating the dependence structure via sample splitting, data screening, and information pooling. The talk details how the SDA filter first constructs a sequence of ranking statistics that fulfill global symmetry properties, and then chooses a data-driven threshold along the ranking to control the FDR.We highlight comparative analyses showing that the SDA filter substantially outperforms the knockoff method in power under moderate to strong dependence, and acts more robustly than existing methods based on asymptotic $p$-values. Furthermore, we examine the finite-sample theory developed in the literature which provides an upper bound for the actual FDR under general dependence, as well as the established asymptotic validity of SDA for both the FDR and false discovery proportion (FDP) control under mild regularity conditions. The procedure is implemented in the R package \texttt{SDA}. Finally, we present numerical results that confirm the effectiveness and robustness of SDA in FDR control, demonstrating substantial power gains over existing methods in many settings.

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">A Brief History of Knockoffs and Their Modern Applications</span>
    <span class="talk-speaker">김규환 (서울대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<h2 class="session-title">
<span class="session-name">☕ Coffee Break</span>

<span class="session-time">10:45–11:00</span>

</h2>

<h2 class="session-title">
<span class="session-name">Session 5: TBA</span>

<span class="session-time">11:00–11:50</span>

</h2>

<details class="talk-card">
    <summary>
    <span class="talk-title">TBA</span>
    <span class="talk-speaker">임예빈 (덕성여대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<details class="talk-card">
    <summary>
    <span class="talk-title">TBA</span>
    <span class="talk-speaker">정윤주 (덕성여대)</span>
    </summary>

    <div class="talk-abstract">
    TBA

    </div>
</details>

<h2 class="session-title">
<span class="session-name">Closing Remark</span>

<span class="session-time">11:50–12:00</span>

</h2>

<h2 class="session-title">
<span class="session-name">Lunch</span>

<span class="session-time">투파인드피터 배곧점</span>

</h2>

<hr />

<h2 id="location">Location</h2>

<p><br /></p>

<h4 id="서울대학교-시흥캠퍼스-컨벤션센터-806호-workshop">서울대학교 시흥캠퍼스 컨벤션센터 806호 (Workshop)</h4>

<!-- * 카카오맵 - 지도퍼가기 -->
<!-- 1. 지도 노드 -->
<div id="daumRoughmapContainer1768018058689" class="root_daum_roughmap root_daum_roughmap_landing" style="width:70%"></div>

<!--
	2. 설치 스크립트
	* 지도 퍼가기 서비스를 2개 이상 넣을 경우, 설치 스크립트는 하나만 삽입합니다.
-->
<script charset="UTF-8" class="daum_roughmap_loader_script" src="https://ssl.daumcdn.net/dmaps/map_js_init/roughmapLoader.js"></script>

<!-- 3. 실행 스크립트 -->
<script charset="UTF-8">
	new daum.roughmap.Lander({  
		"timestamp" : "1768018058689",
		"key" : "fdm46rmtjd8",
		"mapWidth" : "80%",
		"mapHeight" : "300"
	}).render();
</script>

<!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d1489.6365384984156!2d126.71831237291562!3d37.36500091251467!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x357b70e84a95728d%3A0x1dd90cd7498ac1f9!2z7ISc7Jq464yA7ZWZ6rWQIOyLnO2dpey6oO2NvOyKpA!5e0!3m2!1sko!2skr!4v1768007435061!5m2!1sko!2skr" width="80%" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->

<p><br /></p>

<h4 id="돝집-거북섬점-석식">돝집 거북섬점 (석식)</h4>

<!-- * 카카오맵 - 지도퍼가기 -->
<!-- 1. 지도 노드 -->
<div id="daumRoughmapContainer1768018227575" class="root_daum_roughmap root_daum_roughmap_landing" style="width:70%"></div>

<!-- 3. 실행 스크립트 -->
<script charset="UTF-8">
	new daum.roughmap.Lander({
		"timestamp" : "1768018227575",
		"key" : "frc7dx3s2fi",
		"mapWidth" : "80%",
		"mapHeight" : "300"
	}).render();
</script>

<!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3172.7940147177683!2d126.67655072716717!3d37.32370667210244!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x357b75006eb3b8af%3A0xd26e2bfeb4b9e575!2z64-d7KeR!5e0!3m2!1sko!2skr!4v1768007491647!5m2!1sko!2skr" width="80%" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->

<p><br /></p>

<h4 id="시흥-웨이브-엠-호텔-웨스트-호텔-숙박조식">시흥 웨이브 엠 호텔 웨스트 호텔 (숙박/조식)</h4>

<!-- * 카카오맵 - 지도퍼가기 -->
<!-- 1. 지도 노드 -->
<div id="daumRoughmapContainer1768018361511" class="root_daum_roughmap root_daum_roughmap_landing" style="width:70%"></div>

<!-- 3. 실행 스크립트 -->
<script charset="UTF-8">
	new daum.roughmap.Lander({
		"timestamp" : "1768018361511",
		"key" : "fdmba9xddvc",
		"mapWidth" : "80%",
		"mapHeight" : "300"
	}).render();
</script>

<!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3172.9383971279926!2d126.67545637716707!3d37.32028687210339!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x357b75002a8b6fa1%3A0xbc0d7535b1b349d1!2z7Juo7J2067iM7Jeg7Zi47YWUIOybqOyKpO2KuA!5e0!3m2!1sko!2skr!4v1768007571132!5m2!1sko!2skr" width="80%" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->

<p><br /></p>

<h4 id="투파인드피터-배곧점-중식">투파인드피터 배곧점 (중식)</h4>

<!-- * 카카오맵 - 지도퍼가기 -->
<!-- 1. 지도 노드 -->
<div id="daumRoughmapContainer1768018397700" class="root_daum_roughmap root_daum_roughmap_landing" style="width:70%"></div>

<!-- 3. 실행 스크립트 -->
<script charset="UTF-8">
	new daum.roughmap.Lander({
		"timestamp" : "1768018397700",
		"key" : "fdo3baww2h6",
		"mapWidth" : "80%",
		"mapHeight" : "300"
	}).render();
</script>

<!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3170.829996979321!2d126.7244165771686!3d37.37019927208997!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x357b714c38ab5daf%3A0x47b1d58189e97644!2z7Yis7YyM7J2465Oc7ZS87YSwIOuwsOqzp-ygkA!5e0!3m2!1sko!2skr!4v1768007685137!5m2!1sko!2skr" width="80%" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->

<hr />

<p><em>This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (RS-2025-00556575).</em></p>

<!-- 이 성과는 정부(과학기술정보통신부)의 재원으로 한국연구재단의 지원을 받아 수행된 연구임(No. RS-2025-00556575) -->

</div>


    <script id="dsq-count-scr" src="//kordinglab.disqus.com/count.js" async></script>
    <script src="http://code.jquery.com/jquery-2.2.1.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    var pageTracker = _gat._getTracker("UA-34145995-1");
    pageTracker._trackPageview();
    </script>

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-34145995-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-34145995-1');
    </script>

</body>
</html>
